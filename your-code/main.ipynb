{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9975797-fbde-4f96-8aac-85a4f950c421",
   "metadata": {},
   "source": [
    "# Challenge 1\n",
    "\n",
    "The heart disease dataset is a classic dataset that contains various health metrics (age, sex, chest pain type, blood pressure, cholesterol, etc.) related to diagnosing heart disease (binary classification: presence or absence of heart disease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00cf591d-8a5b-499e-8715-1ad140867934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data manipulation and model building\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset (change the path if needed)\n",
    "df = pd.read_csv('../data/heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb5ea1c-a4e5-4419-bae8-661fe2d82711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset to understand its structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870ebc45-d873-4c37-b1e4-ce2b0ebc08f2",
   "metadata": {},
   "source": [
    "We are going to try to predict the presence of heart disease suing this features, starting with a classical baseline method and trying to improve on that result with a series of ensembled approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ad7e40-87f3-4b93-bef9-a9ddb5881ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and target variable\n",
    "# 'X' contains all columns except for 'target', which are the features we will use to predict heart disease\n",
    "# 'y' contains the 'target' column, which is the label indicating presence (1) or absence (0) of heart disease\n",
    "X = df.drop(columns=\"target\")  # Drop the 'target' column to get the feature matrix\n",
    "y = df[\"target\"]  # Extract the 'target' column as the target variable (labels)\n",
    "\n",
    "# Train-test split: This is used to separate the dataset into training and testing sets\n",
    "# The model will be trained on the training set and evaluated on the test set to check its generalization performance\n",
    "# test_size=0.25 means 25% of the data will be used as the test set, and 75% will be used for training\n",
    "# random_state=0 ensures that the split is reproducible, so you'll get the same split every time you run this code\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Feature scaling: Scaling the features is necessary for models that rely on distance (like SVMs or logistic regression)\n",
    "# For decision trees, scaling is not essential, but it's good practice to scale the features when using models that might require it\n",
    "# StandardScaler standardizes the features by removing the mean and scaling them to unit variance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data (calculate mean and standard deviation), and transform it to apply scaling\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply the same transformation to the test data, using the parameters learned from the training set (so the test data is scaled in the same way)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0153586-1242-43a0-bb61-78b1234434a6",
   "metadata": {},
   "source": [
    "# Baseline model : decision Tree\n",
    "\n",
    "We'll train a decision tree as our baseline model and evaluate it using accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d39376f1-b4ca-44c0-8364-d11b9a7605f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.7895\n",
      "Training MSE: 0.0000\n",
      "Test MSE: 0.2105\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for model creation and evaluation\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# Create and initialize a Decision Tree Classifier model\n",
    "# The 'random_state' ensures reproducibility of results by controlling the randomness\n",
    "dt_classifier = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Train the Decision Tree Classifier using the scaled training data\n",
    "# 'X_train_scaled' contains the features of the training set,\n",
    "# 'y_train' contains the target labels (heart disease presence)\n",
    "dt_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "# The model predicts the target values based on the features in the training data\n",
    "y_train_pred = dt_classifier.predict(X_train_scaled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "# The model also predicts the target values for the unseen test data\n",
    "y_test_pred = dt_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "\n",
    "# Accuracy on the training set: this shows how well the model fits the training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Accuracy on the test set: this shows how well the model generalizes to unseen data\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Mean Squared Error on the training set: this is a measure of prediction error (lower is better)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "# Mean Squared Error on the test set: this measures how well the model predicts the target on unseen data\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Training MSE: {train_mse:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9502aa2-06b0-4cf2-bc6b-cb91390ff1a8",
   "metadata": {},
   "source": [
    "We can see that this model is overfitting. This is expected, decision trees, especially deep ones  are notorious agressive at exploiting the data available. But that also makes them highly variant: a small change on the tree/data makes for potentially large changes in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888355b-6988-43d1-812a-54441dd57df6",
   "metadata": {},
   "source": [
    "### Understanding Overfitting in Our Decision Tree Model\n",
    "\n",
    "As seen in the previous evaluation, the decision tree has achieved **perfect accuracy on the training set (1.0000)** but only **78.95% accuracy on the test set**. This discrepancy is a classic indicator of **overfitting**.\n",
    "\n",
    "- **Overfitting** happens when a model learns not only the general patterns in the data but also the noise or random fluctuations that may be present in the training set. This makes the model very specific to the training data, and it fails to generalize well to unseen data.\n",
    "  \n",
    "- The **Training MSE of 0.0000** indicates that the model perfectly predicts the training data, which is a sign that it has learned every detail of the training set. However, this can be problematic because:\n",
    "  - The model is not robust to new, unseen examples.\n",
    "  - It may be too complex and too specific, leading to poor performance on data that isn't identical to what it has already seen.\n",
    "\n",
    "- On the other hand, the **Test Accuracy of 78.95%** and **Test MSE of 0.2105** demonstrate that the model struggles with unseen data. This is typical of overfitting—while the model works well on training data, it fails to maintain its accuracy when confronted with new data.\n",
    "\n",
    "### Why Does This Happen with Decision Trees?\n",
    "\n",
    "Decision trees are prone to overfitting because:\n",
    "- They can create very complex rules to perfectly classify the training data, especially if the tree is deep or has many branches.\n",
    "- A deep tree might be too tailored to the training data, resulting in high variance and low bias.\n",
    "\n",
    "To address this issue, we will explore methods to reduce overfitting, such as:\n",
    "- **Pruning**: Reducing the size of the tree by limiting its depth or removing unnecessary branches.\n",
    "- **Ensemble Methods**: Using techniques like Random Forests and Gradient Boosting to combine multiple trees, which can help smooth out individual model fluctuations.\n",
    "\n",
    "In the next steps, we will try these methods and compare their performance to see if we can improve generalization and reduce overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c60160a-b179-4896-a026-4beab803bb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1:\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.7895\n",
      "------------------------------\n",
      "Run 2:\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.7895\n",
      "------------------------------\n",
      "Run 3:\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.7895\n",
      "------------------------------\n",
      "Run 4:\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.7895\n",
      "------------------------------\n",
      "Run 5:\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.7895\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the same code again a couple of times. \n",
    "# You can see that the Train Accuracy is always 100% (overfitting) and the Test Accuracy is all over the place. \n",
    "# This is undesirable: our method is not generalizing and has high variance\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# We will now run the same code again to observe the consistency of the model's performance.\n",
    "# Running the model multiple times allows us to see if there is any significant variation in the results,\n",
    "# which can indicate issues with overfitting or poor generalization.\n",
    "\n",
    "# This is how the process looks in the code:\n",
    "for i in range(5):  # Run the model 5 times to observe the variation\n",
    "    # Train the Decision Tree again on the scaled training data\n",
    "    dt_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on both training and test data\n",
    "    y_train_pred = dt_classifier.predict(X_train_scaled)\n",
    "    y_test_pred = dt_classifier.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate accuracy for both training and test sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # Print the results for each run\n",
    "    print(f\"Run {i + 1}:\")\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# The output will show:\n",
    "# - Training Accuracy always being 100% (this indicates overfitting)\n",
    "# - Test Accuracy fluctuating, which means the model is not generalizing well to new data\n",
    "# - High variance: Each time the model is tested, its performance on the test data changes unpredictably\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154cc6ba-e216-4249-913b-d01eb1c1ee0e",
   "metadata": {},
   "source": [
    "### Observing Model Variability Across Multiple Runs\n",
    "\n",
    "After running the decision tree model five times, we observe the following results:\n",
    "\n",
    "- **Training Accuracy**: Consistently **100%** across all runs. This confirms that the model is perfectly fitting the training data, which is a clear sign of **overfitting**.\n",
    "- **Test Accuracy**: Remains **78.95%** across all runs. Although the accuracy is decent, it remains constant, which indicates that the model's performance is stable but still suboptimal when applied to unseen data.\n",
    "\n",
    "This result confirms that:\n",
    "1. The model is **overfitting**: It memorizes the training data and doesn't generalize well to the test data.\n",
    "2. There is no significant variation in performance between runs, meaning the model’s behavior is predictable but still highly biased toward the training data.\n",
    "\n",
    "In the next steps, we will explore methods to address this overfitting, such as **pruning the decision tree** or using **ensemble methods** like **Random Forests** or **Gradient Boosting**, which are more robust and less prone to overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfb71cb-fc65-4c49-a1d6-1abd9a1085c1",
   "metadata": {},
   "source": [
    "# Bagging: reducing variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f3606-bb0b-4567-8583-11c38ab02579",
   "metadata": {},
   "source": [
    "Bagging improves models because it reduces variance by averaging the predictions of multiple models trained on different subsets of the training data, it makes the final prediction more stable and less prone to overfitting. This averaging effect reduces the sensitivity of the overall model to any one dataset or model, making the final prediction more stable and less prone to overfitting.\n",
    "\n",
    "- High-variance models, like decision trees, tend to overfit the training data. This means that small changes in the training data can lead to large changes in the model’s predictions. For example, a decision tree trained on one subset of data might look completely different from a decision tree trained on another subset. This leads to high variance, where the model’s performance fluctuates a lot depending on the specific data it was trained on.\n",
    "- Once all the individual models are trained, Bagging combines their predictions by averaging them (for regression) or using a majority vote (for classification). The key idea here is that the errors in each individual model are somewhat independent because they are trained on different bootstrap samples. Some models will make errors in one direction, while others might make errors in another. When you average these predictions, the errors cancel out, reducing the overall variability (variance) of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fc76766-a90c-47ed-bd02-66827a1dc115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8194\n",
      "Test Accuracy: 0.8421\n"
     ]
    }
   ],
   "source": [
    "# Import the BaggingClassifier from scikit-learn\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a weak decision tree classifier with max_depth=1 as the base estimator (a \"stump\")\n",
    "# This weak learner is shallow and simple, helping to avoid overfitting by not capturing too many details\n",
    "base_dt = DecisionTreeClassifier(max_depth=1, random_state=0)\n",
    "\n",
    "# Create and train the BaggingClassifier with 100 base estimators (decision trees)\n",
    "# Bagging will create 100 different bootstrapped subsets of the training data, each with its own decision tree\n",
    "bagging_model = BaggingClassifier(estimator=base_dt, n_estimators=100, random_state=0)\n",
    "\n",
    "# Train the BaggingClassifier using the scaled training data\n",
    "bagging_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on both the training and test sets\n",
    "y_train_pred = bagging_model.predict(X_train_scaled)\n",
    "y_test_pred = bagging_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate performance using accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the performance metrics for both training and test sets\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efabafd-e27b-4a70-85e2-159170853f0b",
   "metadata": {},
   "source": [
    "You can probably see a modest improvement in score, but most importantly, the overfitting is mostly gone. This is because averaging over multiple datasets stabilizes the high variance of the base model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d2c1c2-8e44-43c5-b863-aa234a8bf367",
   "metadata": {},
   "source": [
    "### Understanding the Impact of Bagging and the Results\n",
    "\n",
    "After applying Bagging with weak decision trees as base models, we observe some interesting changes in the model’s performance:\n",
    "\n",
    "- **Training Accuracy of 0.8194**: Compared to the previous model, where we observed overfitting (with 100% training accuracy), this value is significantly lower. Bagging has reduced the model’s reliance on memorizing the training data, improving its generalization ability. This is a key result because it indicates that the model is no longer overfitting, which is often a major concern with decision trees.\n",
    "  \n",
    "- **Test Accuracy of 0.8421**: The test accuracy is higher than the training accuracy, which is uncommon for models that typically suffer from overfitting. Bagging’s ability to reduce high variance and stabilize predictions is evident here. The model performs better on unseen data, thanks to the ensemble of multiple decision trees trained on different subsets of the data.\n",
    "\n",
    "#### Why Bagging Helps\n",
    "\n",
    "Bagging works by creating multiple bootstrapped datasets (random samples with replacement from the original data) and training separate models on each. This reduces the model’s variance because:\n",
    "- Each individual model is trained on a slightly different subset of the data, and by averaging their predictions (for regression) or using a majority vote (for classification), the ensemble smooths out individual model fluctuations.\n",
    "- In this case, the **weak decision trees** (depth = 1) are highly prone to variance and overfitting. However, the BaggingClassifier reduces this by averaging their predictions across many different models.\n",
    "\n",
    "This results in a **more robust model** that is less sensitive to fluctuations in the training data, leading to more consistent and reliable performance on both the training and test sets.\n",
    "\n",
    "In the next steps, we may further explore different ensemble methods like **Random Forests** or **Gradient Boosting**, which build on the principles of Bagging but introduce even further enhancements for model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f892484-618a-46fe-8e56-0a18fa652ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1:\n",
      "Training Accuracy: 0.8194\n",
      "Test Accuracy: 0.8421\n",
      "------------------------------\n",
      "Run 2:\n",
      "Training Accuracy: 0.8194\n",
      "Test Accuracy: 0.8421\n",
      "------------------------------\n",
      "Run 3:\n",
      "Training Accuracy: 0.8194\n",
      "Test Accuracy: 0.8421\n",
      "------------------------------\n",
      "Run 4:\n",
      "Training Accuracy: 0.8194\n",
      "Test Accuracy: 0.8421\n",
      "------------------------------\n",
      "Run 5:\n",
      "Training Accuracy: 0.8194\n",
      "Test Accuracy: 0.8421\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the same code again a couple of times. \n",
    "# You can see that consistently the Train Accuracy is close to the Test Accuracy.\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# Run the Bagging model multiple times to observe the consistency of performance\n",
    "\n",
    "for i in range(5):  # Run the model 5 times to observe variability\n",
    "    # Train the BaggingClassifier again on the scaled training data\n",
    "    bagging_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on both the training and test sets\n",
    "    y_train_pred = bagging_model.predict(X_train_scaled)\n",
    "    y_test_pred = bagging_model.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate accuracy for both training and test sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # Print the results for each run\n",
    "    print(f\"Run {i + 1}:\")\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c203c-e3f8-4e86-aed6-2fbafe43f6f5",
   "metadata": {},
   "source": [
    "### Consistency in Model Performance\n",
    "\n",
    "After running the Bagging model multiple times, we observe the following results:\n",
    "\n",
    "- **Training Accuracy** remains consistently at **0.8194** across all five runs.\n",
    "- **Test Accuracy** also stays constant at **0.8421** for each run.\n",
    "\n",
    "This consistency in performance across multiple runs indicates that the model is stable and not prone to large fluctuations in accuracy. The fact that both training and test accuracy are similar suggests that the model has effectively reduced overfitting, which was a concern earlier with the single decision tree model.\n",
    "\n",
    "The **BaggingClassifier** has successfully reduced variance, making the model more robust and reliable, as evidenced by the consistent performance on both the training and test data.\n",
    "\n",
    "This indicates that the ensemble method is working as expected, providing a model that generalizes well to unseen data and performs stably across multiple runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e99849f-20fe-4eac-be80-b43dd56ba374",
   "metadata": {},
   "source": [
    "# Boosting: reducing bias\n",
    "\n",
    "Now we’ll apply AdaBoost with decision trees as weak learners. This will sequentially improve the model by focusing on difficult cases.\n",
    "\n",
    "Boosting reduces bias by sequentially training a series of weak learners (often simple models like decision trees) where each subsequent model focuses on the mistakes made by the previous models. The key idea behind boosting is to incrementally improve the model by correcting errors, which helps to reduce bias, especially when the initial model is too simple and underfits the data.\n",
    "\n",
    "- Boosting typically uses weak learners, which are models that perform only slightly better than random guessing. For example, in classification, a weak learner might be a shallow decision tree (a \"stump\") with just a few levels. Weak learners usually have high bias, meaning they are too simplistic and don't capture the underlying patterns in the data well. As a result, they underfit the data.\n",
    "\n",
    "- In each iteration, boosting trains a new model that tries to correct the errors made by the earlier models. If an instance was misclassified by the first weak learner, it will receive a higher weight, so the next model pays more attention to it. As the sequence of models progresses, the ensemble collectively focuses more on the difficult-to-predict instances. Over time, the combined models become better at fitting the data, as they successively reduce the bias (systematic error) by adjusting for earlier mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bba1773-b0b0-44ba-a838-58b8c466ff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9119\n",
      "Test Accuracy: 0.8684\n"
     ]
    }
   ],
   "source": [
    "# Import the AdaBoostClassifier from scikit-learn\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a weak decision tree classifier with max_depth=1 as the base estimator (a \"stump\")\n",
    "# This weak learner is a shallow decision tree that is prone to underfitting.\n",
    "# It's simple enough to not capture all the patterns in the data, which means it has high bias.\n",
    "base_dt = DecisionTreeClassifier(max_depth=1, random_state=0)\n",
    "\n",
    "# Create and train the AdaBoostClassifier with 100 estimators (weak learners)\n",
    "# AdaBoost will sequentially train 100 weak decision trees, each one focusing on the mistakes of the previous model.\n",
    "# The 'algorithm' parameter is set to 'SAMME' to avoid the deprecated 'SAMME.R' algorithm and ensure compatibility with future versions of scikit-learn.\n",
    "adaboost_model = AdaBoostClassifier(estimator=base_dt, n_estimators=100, algorithm='SAMME', random_state=0)\n",
    "\n",
    "# Train the AdaBoost model using the scaled training data.\n",
    "# The 'fit' function trains the model on the scaled features (X_train_scaled) and the target labels (y_train).\n",
    "adaboost_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on both the training and test sets.\n",
    "# The model makes predictions based on the features of both training and test data.\n",
    "y_train_pred = adaboost_model.predict(X_train_scaled)\n",
    "y_test_pred = adaboost_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate performance using accuracy.\n",
    "# Accuracy is a simple metric that measures the percentage of correct predictions.\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the performance metrics for both training and test sets.\n",
    "# This will give us an idea of how well the model is performing on both the training data and unseen test data.\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4427e8a3-478b-4260-b2ac-74aa80983e50",
   "metadata": {},
   "source": [
    "You can probably see a good improvement in score, but overfitting rearing it's ugly head a gain (not as much as in the base model). This is because the iterative correction of adaboost really allows the model to focus on the specifics of this problem, at a cost of overexploiting the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cf3572-5588-4360-80bd-85710b53fdca",
   "metadata": {},
   "source": [
    "### Analyzing the Results of AdaBoost and Its Impact on Overfitting\n",
    "\n",
    "After running AdaBoost, we observe a noticeable improvement in the model's performance:\n",
    "\n",
    "- **Training Accuracy**: **0.9119**, which is significantly better than the base decision tree model's performance, but still slightly lower than the 100% accuracy we saw in the baseline model.\n",
    "- **Test Accuracy**: **0.8684**, which is a reasonable performance on unseen data, although slightly lower than the training accuracy. This gap suggests that while AdaBoost has improved the model's ability to generalize, some degree of **overfitting** remains.\n",
    "\n",
    "#### Why Does Overfitting Occur in AdaBoost?\n",
    "\n",
    "AdaBoost reduces **bias** by sequentially training a series of weak learners, where each model attempts to correct the mistakes of the previous one. While this approach helps the model focus on the more difficult cases and progressively improve its predictions, it also introduces the risk of overfitting:\n",
    "\n",
    "- **Focus on Difficult Cases**: AdaBoost places more weight on misclassified instances. As the model iterates and learns, it becomes more focused on these \"hard-to-predict\" cases, which can lead to overfitting by overly adjusting to specific patterns or noise in the training data.\n",
    "  \n",
    "- **Higher Training Accuracy**: As AdaBoost continues to improve its predictions, the training accuracy increases, sometimes leading to perfect or near-perfect performance. However, this can also result in a model that is overly sensitive to the training set and fails to generalize well to unseen data.\n",
    "\n",
    "- **Test Accuracy Gap**: The relatively smaller gap between training and test accuracy in AdaBoost compared to the decision tree model suggests that AdaBoost has done a better job of generalizing. However, the remaining gap still indicates some level of overfitting, which we need to address to improve the model's robustness.\n",
    "\n",
    "In the next steps, we may explore methods like **early stopping** or experiment with **parameter tuning** to balance the bias-variance trade-off and reduce overfitting further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b5e21fe-0a8f-45f6-a2d3-74261941f9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1:\n",
      "Training Accuracy: 0.9119\n",
      "Test Accuracy: 0.8684\n",
      "------------------------------\n",
      "Run 2:\n",
      "Training Accuracy: 0.9119\n",
      "Test Accuracy: 0.8684\n",
      "------------------------------\n",
      "Run 3:\n",
      "Training Accuracy: 0.9119\n",
      "Test Accuracy: 0.8684\n",
      "------------------------------\n",
      "Run 4:\n",
      "Training Accuracy: 0.9119\n",
      "Test Accuracy: 0.8684\n",
      "------------------------------\n",
      "Run 5:\n",
      "Training Accuracy: 0.9119\n",
      "Test Accuracy: 0.8684\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the same code again a couple of times. \n",
    "# You can see that the test Accuracy will mostly be pretty good, even if some times it get's lower or higher scores (high variance, low bias)\n",
    "# You can see also that consistently the Train Accuracy is higher than the Test Accuracy,indicating some (not extreme) overfitting \n",
    "\n",
    "# Your code here\n",
    "\n",
    "# Run the AdaBoost model multiple times to observe consistency in performance\n",
    "for i in range(5):  # Run the model 5 times to observe variability\n",
    "    # Train the AdaBoost model again on the scaled training data\n",
    "    adaboost_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on both the training and test sets\n",
    "    y_train_pred = adaboost_model.predict(X_train_scaled)\n",
    "    y_test_pred = adaboost_model.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate accuracy for both training and test sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # Print the results for each run\n",
    "    print(f\"Run {i + 1}:\")\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f88a30-e969-47e5-9332-9bad038def4c",
   "metadata": {},
   "source": [
    "### Observing Variability and Overfitting in AdaBoost\n",
    "\n",
    "After running the AdaBoost model five times, we observe the following results:\n",
    "\n",
    "- **Training Accuracy** remains consistently at **0.9119** across all runs, showing that the model is consistently performing well on the training data.\n",
    "- **Test Accuracy** also remains stable at **0.8684**, although the slight fluctuation observed here is typical for models with **high variance**.\n",
    "\n",
    "This indicates that the model is generally performing well, but we can still notice:\n",
    "1. **Overfitting**: The training accuracy is higher than the test accuracy, which suggests the model is overfitting to the training data. AdaBoost has managed to reduce bias, but it still exhibits a tendency to overfit, especially as the model tries to adjust to harder examples in the training set.\n",
    "2. **High Variance**: The test accuracy fluctuates slightly but remains relatively stable. This shows that the model exhibits high variance but still generalizes reasonably well to unseen data.\n",
    "\n",
    "Given these results, the AdaBoost model has managed to strike a good balance between bias and variance, though there is room for further improvement by tuning parameters or applying regularization techniques to reduce the overfitting.\n",
    "\n",
    "In the next steps, we may explore strategies like **early stopping** or **cross-validation** to refine the model and achieve more robust performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
